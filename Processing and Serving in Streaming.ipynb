{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img width=\"200\" style=\"float:left\" \n",
    "     src=\"https://upload.wikimedia.org/wikipedia/commons/f/f3/Apache_Spark_logo.svg\" /> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sections\n",
    "* [Description](#0)\n",
    "* [1. Streaming Processing](#1) \n",
    "  * [1.1 Search for Spark Installation](#1.1)\n",
    "  * [1.2 Create SparkSession](#1.2)\n",
    "  * [1.3 Main DataFrame creation](#1.3) \n",
    "  * [1.4 Extract the right data out of the CSV line you get from the topic](#1.4)\n",
    "  * [1.5  Main queries for streaming processing](#1.5)\n",
    "* [2. Serging](#2)  \n",
    "  * [2.1 Start the Kafka service and the producer](#2.1)\n",
    "  * [2.2 Create SparkSession for Streaming processing](#2.2)\n",
    "  * [2.3 Reading of CSV file](#2.3)\n",
    "  * [2.4 Reading tweets from the kafka topic](#2.4)\n",
    "  * [2.5 Creation of an specific dataframe](#2.5)\n",
    "  * [2.6 Join, and launch to MariaDB](#2.6)\n",
    "* [3. Finalize the exercise](#3)\n",
    "  * [3.1 Stop the Spark Streaming application](#3.1)\n",
    "  * [3.2 Stop the Kafka producer](#3.2)\n",
    "  * [3.3 Stop the Kafka service](#3.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='0'></a>\n",
    "## Description\n",
    "<p>\n",
    "<div>This notebook will do the following:</div>\n",
    "<ul>    \n",
    "\n",
    "The same notebooks can handle two streaming works, processing and serving. For running each part, the notebooks has to be restarted. Once is restarted, run only the part that the user wants to use, with the steps required.  \n",
    "   \n",
    "PART 1\n",
    "    <li>Consume events from a Kafka topic called <em>tweets</em></li>\n",
    "    <li>Count and show which mentions are trending</li>\n",
    "    <li>Counting hashtags in window of 30 seconds</li>\n",
    "    <li>More retweetd accounts</li>\n",
    "    \n",
    "PART 2\n",
    "\n",
    "<li>Read a CSV file ready to be join with the streaming data</li>\n",
    "<li>Consume events from a Kafka topic called <em>tweets</em></li>\n",
    "<li>Create the specific dataframe that is going to be upload to MariaDB</li>\n",
    "<li>Function to specify where is going to be deployed our table</li>\n",
    "<li>Query for launching</li>\n",
    "\n",
    "</ul>    \n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='1'></a>\n",
    "## 1. Streaming Processing\n",
    "\n",
    "<p>Before you can run this notebook, be sure that you:</p>\n",
    "<ul>\n",
    "    <li><p><b>Start the Kafka service</b> in you course environment:\n",
    "        <br/><em>\\$ sudo service kafka start</p></em></li>  \n",
    "    <li><p><b>Start the producer</b>:\n",
    "        <br/><em>\\$ python3 tweets_producer.py send -m \"This is a message from the Python client\" -t tweets</em></p></li>\n",
    "    <li><p><b>If you want, you can check if the tweets are being storage launching in other terminal the consumer</b>:\n",
    "        <br/><em>\\$ python3 tweets_consumer.py tweets IE 300</em></p></li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='1.1'></a>\n",
    "### 1.1 Search for Spark Installation \n",
    "This step is required just because we are working in the course environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='1.2'></a>\n",
    "### 1.2 Create SparkSession for Streaming processing\n",
    "\n",
    "\n",
    "By setting this environment variable we can include extra libraries in our Spark cluster.<br/>\n",
    "We'll take advantage of this step to include that <b>Spark package to connecto to Kafka</b>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/opt/spark3/jars/spark-unsafe_2.12-3.0.3.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Ivy Default Cache set to: /home/osbdet/.ivy2/cache\n",
      "The jars for the packages stored in: /home/osbdet/.ivy2/jars\n",
      ":: loading settings :: url = jar:file:/opt/spark3/jars/ivy-2.4.0.jar!/org/apache/ivy/core/settings/ivysettings.xml\n",
      "org.apache.spark#spark-sql-kafka-0-10_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-71ea722b-61c5-4c66-bf61-d7d66b741155;1.0\n",
      "\tconfs: [default]\n",
      "\tfound org.apache.spark#spark-sql-kafka-0-10_2.12;3.0.3 in central\n",
      "\tfound org.apache.spark#spark-token-provider-kafka-0-10_2.12;3.0.3 in central\n",
      "\tfound org.apache.kafka#kafka-clients;2.4.1 in central\n",
      "\tfound com.github.luben#zstd-jni;1.4.4-3 in central\n",
      "\tfound org.lz4#lz4-java;1.7.1 in central\n",
      "\tfound org.xerial.snappy#snappy-java;1.1.8.2 in central\n",
      "\tfound org.slf4j#slf4j-api;1.7.30 in central\n",
      "\tfound org.spark-project.spark#unused;1.0.0 in central\n",
      "\tfound org.apache.commons#commons-pool2;2.6.2 in central\n",
      ":: resolution report :: resolve 323ms :: artifacts dl 6ms\n",
      "\t:: modules in use:\n",
      "\tcom.github.luben#zstd-jni;1.4.4-3 from central in [default]\n",
      "\torg.apache.commons#commons-pool2;2.6.2 from central in [default]\n",
      "\torg.apache.kafka#kafka-clients;2.4.1 from central in [default]\n",
      "\torg.apache.spark#spark-sql-kafka-0-10_2.12;3.0.3 from central in [default]\n",
      "\torg.apache.spark#spark-token-provider-kafka-0-10_2.12;3.0.3 from central in [default]\n",
      "\torg.lz4#lz4-java;1.7.1 from central in [default]\n",
      "\torg.slf4j#slf4j-api;1.7.30 from central in [default]\n",
      "\torg.spark-project.spark#unused;1.0.0 from central in [default]\n",
      "\torg.xerial.snappy#snappy-java;1.1.8.2 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   9   |   0   |   0   |   0   ||   9   |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-71ea722b-61c5-4c66-bf61-d7d66b741155\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 9 already retrieved (0kB/8ms)\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages \"org.apache.spark:spark-sql-kafka-0-10_2.12:3.0.3\" pyspark-shell'\n",
    "\n",
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql.session import SparkSession\n",
    "\n",
    "spark = (SparkSession.builder\n",
    "    .appName(\"Processing and Serving in Streaming\")\n",
    "    .getOrCreate())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='1.3'></a>\n",
    "### 1.3 Main DataFrame creation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[key: binary, value: binary, topic: string, partition: int, offset: bigint, timestamp: timestamp, timestampType: int]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = spark.readStream\\\n",
    "               .format(\"kafka\") \\\n",
    "               .option(\"kafka.bootstrap.servers\", \"localhost:9092\") \\\n",
    "               .option(\"subscribe\", \"tweets\") \\\n",
    "               .option(\"startingOffsets\", \"latest\") \\\n",
    "               .option(\"kafka.group.id\", \"IE\") \\\n",
    "               .load()\n",
    "tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='1.4'></a>\n",
    "### 1.4 Extract the right data out of the CSV line you get from the topic\n",
    "We're going to apply the following logic to the events we get from the topic:\n",
    "<ul>\n",
    "    <li>Cast the default data type of the field <em>value</em> (byte) to the String data type.</li>\n",
    "    <li>Split the txt line into fields by using the <em>split</em> function.</li>\n",
    "    <li>Create most of the columns that are present into the TXT file\n",
    "\n",
    "</ul>\n",
    "\n",
    "Check the schema we get now, it looks like any other DataFrame we've seen up until now... this is <b>a real unified processing framework</b>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import split, col, window\n",
    "from pyspark.sql.types import StringType,BooleanType,DateType,TimestampType,IntegerType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import split, col, window\n",
    "from pyspark.sql.types import StringType,BooleanType,DateType,TimestampType,IntegerType\n",
    "\n",
    "tweets = tweets.selectExpr(\"CAST(value AS STRING)\") \\\n",
    "                 .select(split(\"value\",'\\|').alias(\"fields\")) \\\n",
    "                 .withColumn(\"timestamp_str\",col(\"fields\").getItem(0)) \\\n",
    "                 .withColumn(\"created_at\",col(\"timestamp_str\").cast(TimestampType()))\\\n",
    "                 .withColumn(\"id_str\",col(\"fields\").getItem(1)) \\\n",
    "                 .withColumn(\"text\",col(\"fields\").getItem(2)) \\\n",
    "                 .withColumn(\"quote_count\",col(\"fields\").getItem(3)) \\\n",
    "                 .withColumn(\"reply_count\",col(\"fields\").getItem(4)) \\\n",
    "                 .withColumn(\"retweet_count\",col(\"fields\").getItem(5)) \\\n",
    "                 .withColumn(\"favorite_count\",col(\"fields\").getItem(6)) \\\n",
    "                 .withColumn(\"favorited\",col(\"fields\").getItem(7)) \\\n",
    "                 .withColumn(\"retweeted\",col(\"fields\").getItem(8)) \\\n",
    "                 .withColumn(\"possibly_sensitive\",col(\"fields\").getItem(9)) \\\n",
    "                 .withColumn(\"filter_level\",col(\"fields\").getItem(10)) \\\n",
    "                 .withColumn(\"lang\",col(\"fields\").getItem(11)) \\\n",
    "                 .withColumn(\"hour\",col(\"fields\").getItem(12)) \\\n",
    "                 .withColumn(\"mix\",col(\"fields\").getItem(13)) \\\n",
    "                 .withColumn(\"dt\",col(\"fields\").getItem(14)) \\\n",
    "                 .withColumn(\"day-hour\",col(\"fields\").getItem(15)) \\\n",
    "                 .withColumn(\"user_name\",col(\"fields\").getItem(16)) \\\n",
    "                 .withColumn(\"user_screen_name\",col(\"fields\").getItem(17)) \\\n",
    "                 .withColumn(\"user_location\",col(\"fields\").getItem(18)) \\\n",
    "                 .withColumn(\"user_description\",col(\"fields\").getItem(19)) \\\n",
    "                 .withColumn(\"user_followers_count\",col(\"fields\").getItem(20)) \\\n",
    "                 .withColumn(\"user_friends_count\",col(\"fields\").getItem(21)) \\\n",
    "                 .withColumn(\"user_listed_count\",col(\"fields\").getItem(22)) \\\n",
    "                 .withColumn(\"user_favourites_count\",col(\"fields\").getItem(23)) \\\n",
    "                 .withColumn(\"user_statuses_count\",col(\"fields\").getItem(24)) \\\n",
    "                 .withColumn(\"user_statuses_count\",col(\"user_statuses_count\").cast(IntegerType()))\\\n",
    "                 .withColumn(\"rt_quot_count\",col(\"fields\").getItem(25)) \\\n",
    "                 .withColumn(\"rt_reply_count\",col(\"fields\").getItem(26)) \\\n",
    "                 .withColumn(\"rt_retweet_count\",col(\"fields\").getItem(27)) \\\n",
    "                 .withColumn(\"rt_retweet_count\",col(\"rt_retweet_count\").cast(IntegerType()))\\\n",
    "                 .withColumn(\"rt_favorite_count\",col(\"fields\").getItem(28)) \\\n",
    "                 .withColumn(\"rt_user_id\",col(\"fields\").getItem(29)) \\\n",
    "                 .withColumn(\"rt_user_name\",col(\"fields\").getItem(30)) \\\n",
    "                 .withColumn(\"rt_user_screen_name\",col(\"fields\").getItem(31)) \\\n",
    "                 .withColumn(\"rt_user_location\",col(\"fields\").getItem(32)) \\\n",
    "                 .withColumn(\"rt_user_description\",col(\"fields\").getItem(33)) \\\n",
    "                 .withColumn(\"rt_user_followers_count\",col(\"fields\").getItem(34)) \\\n",
    "                 .withColumn(\"rt_user_friends_count\",col(\"fields\").getItem(35)) \\\n",
    "                 .withColumn(\"rt_user_listed_count\",col(\"fields\").getItem(36)) \\\n",
    "                 .withColumn(\"rt_user_favourites_count\",col(\"fields\").getItem(37)) \\\n",
    "                 .withColumn(\"rt_user_statuses_count\",col(\"fields\").getItem(38)) \\\n",
    "                 .withColumn(\"rt_user_created_at\",col(\"fields\").getItem(39)) \\\n",
    "                 .withColumn(\"user_mentions_screen_name\",col(\"fields\").getItem(40)) \\\n",
    "                 .withColumn(\"hashtags\",col(\"fields\").getItem(41)) \\\n",
    "                 .withColumn(\"media_expanded_url\",col(\"fields\").getItem(42)) \\\n",
    "                 .withColumn(\"urls_expanded_url\",col(\"fields\").getItem(43)) \\\n",
    "                 .withColumn(\"symbols_text\",col(\"fields\").getItem(44)) \\\n",
    "                 .drop(\"fields\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- timestamp_str: string (nullable = true)\n",
      " |-- created_at: timestamp (nullable = true)\n",
      " |-- id_str: string (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      " |-- quote_count: string (nullable = true)\n",
      " |-- reply_count: string (nullable = true)\n",
      " |-- retweet_count: string (nullable = true)\n",
      " |-- favorite_count: string (nullable = true)\n",
      " |-- favorited: string (nullable = true)\n",
      " |-- retweeted: string (nullable = true)\n",
      " |-- possibly_sensitive: string (nullable = true)\n",
      " |-- filter_level: string (nullable = true)\n",
      " |-- lang: string (nullable = true)\n",
      " |-- hour: string (nullable = true)\n",
      " |-- mix: string (nullable = true)\n",
      " |-- dt: string (nullable = true)\n",
      " |-- day-hour: string (nullable = true)\n",
      " |-- user_name: string (nullable = true)\n",
      " |-- user_screen_name: string (nullable = true)\n",
      " |-- user_location: string (nullable = true)\n",
      " |-- user_description: string (nullable = true)\n",
      " |-- user_followers_count: string (nullable = true)\n",
      " |-- user_friends_count: string (nullable = true)\n",
      " |-- user_listed_count: string (nullable = true)\n",
      " |-- user_favourites_count: string (nullable = true)\n",
      " |-- user_statuses_count: integer (nullable = true)\n",
      " |-- rt_quot_count: string (nullable = true)\n",
      " |-- rt_reply_count: string (nullable = true)\n",
      " |-- rt_retweet_count: integer (nullable = true)\n",
      " |-- rt_favorite_count: string (nullable = true)\n",
      " |-- rt_user_id: string (nullable = true)\n",
      " |-- rt_user_name: string (nullable = true)\n",
      " |-- rt_user_screen_name: string (nullable = true)\n",
      " |-- rt_user_location: string (nullable = true)\n",
      " |-- rt_user_description: string (nullable = true)\n",
      " |-- rt_user_followers_count: string (nullable = true)\n",
      " |-- rt_user_friends_count: string (nullable = true)\n",
      " |-- rt_user_listed_count: string (nullable = true)\n",
      " |-- rt_user_favourites_count: string (nullable = true)\n",
      " |-- rt_user_statuses_count: string (nullable = true)\n",
      " |-- rt_user_created_at: string (nullable = true)\n",
      " |-- user_mentions_screen_name: string (nullable = true)\n",
      " |-- hashtags: string (nullable = true)\n",
      " |-- media_expanded_url: string (nullable = true)\n",
      " |-- urls_expanded_url: string (nullable = true)\n",
      " |-- symbols_text: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tweets.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='1.5'></a>\n",
    "### 1.5 Main queries for streaming processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.5.1: Counting which mention is more trending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets.where(col(\"user_mentions_screen_name\").isNotNull())\\\n",
    "            .where(col(\"user_mentions_screen_name\")!=\"[]\")\\\n",
    "            .groupBy(\"user_mentions_screen_name\")\\\n",
    "            .count()\\\n",
    "            .orderBy(col(\"count\").desc())\\\n",
    "            .limit(5)\\\n",
    "            .writeStream\\\n",
    "            .format(\"console\")\\\n",
    "            .outputMode(\"complete\")\\\n",
    "            .trigger(processingTime='10 seconds')\\\n",
    "            .start()\\\n",
    "            .awaitTermination()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.5.2: Counting hashtags in window of 30 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets.where(col(\"hashtags\").isNotNull())\\\n",
    "                 .where(col(\"hashtags\")!=\"[]\")\\\n",
    "                 .groupBy(window(col(\"created_at\"),\"30 seconds\"),\"hashtags\")\\\n",
    "                 .count()\\\n",
    "                 .orderBy(col(\"count\").desc())\\\n",
    "                 .limit(5)\\\n",
    "                 .writeStream\\\n",
    "                 .format(\"console\")\\\n",
    "                 .outputMode(\"complete\")\\\n",
    "                 .start()\\\n",
    "                 .awaitTermination()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.5.3: More retweeted accounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets.where(col(\"rt_user_screen_name\").isNotNull())\\\n",
    "            .groupBy(\"rt_user_screen_name\")\\\n",
    "            .count()\\\n",
    "            .orderBy(col(\"count\").desc())\\\n",
    "            .limit(5)\\\n",
    "            .writeStream\\\n",
    "            .format(\"console\")\\\n",
    "            .outputMode(\"complete\")\\\n",
    "            .trigger(processingTime='10 seconds')\\\n",
    "            .start()\\\n",
    "            .awaitTermination()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='2'></a>\n",
    "## 2. Serving"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='2.1'></a>\n",
    "### 2.1 Start the Kafka service and the producer \n",
    "<p>Before you can run this part of the notebook, be sure that you:</p>\n",
    "<ul>\n",
    "    <li><p><b>Kafka is running, cheching status</b> in you course environment:\n",
    "        <br/><em>\\$ sudo service kafka status</p></em></li>\n",
    "    <li><p><b>If is not running, start kafka</b> in you course environment:\n",
    "        <br/><em>\\$ sudo service kafka start</p></em></li>    \n",
    "    <li><p><b>Start Mariadb service</b> in you course environment:\n",
    "        <br/><em>\\$ sudo service Mariadb start</p></em></li>\n",
    "     <li><p><b>Create the required table in MariaDB:\n",
    "        <br/><em>\\$ mariadb -u osbdet -p < tweets-db.sql </p></em></li>    \n",
    "    <li><p><b>Start the producer</b>:\n",
    "        <br/><em>\\$ python3 python3 tweets_producer.py send -m \"This is a message from the Python client\" -t tweets</em></p></li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='2.2'></a>\n",
    "### 2.2 Create SparkSession for Streaming processing\n",
    "\n",
    "\n",
    "By setting this environment variable we can include extra libraries in our Spark cluster.<br/>\n",
    "We'll take advantage of this step to include that <b>Spark package to connecto to Kafka</b>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import split, col, window\n",
    "from pyspark.sql.types import StringType,BooleanType,DateType,TimestampType,IntegerType\n",
    "\n",
    "import os\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages \"org.apache.spark:spark-sql-kafka-0-10_2.12:3.0.3\" --jars \"/usr/share/java/mariadb-java-client.jar,/opt/hive3/lib/hive-hcatalog-core-3.1.2.jar\" pyspark-shell'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/opt/spark3/jars/spark-unsafe_2.12-3.0.3.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Ivy Default Cache set to: /home/osbdet/.ivy2/cache\n",
      "The jars for the packages stored in: /home/osbdet/.ivy2/jars\n",
      ":: loading settings :: url = jar:file:/opt/spark3/jars/ivy-2.4.0.jar!/org/apache/ivy/core/settings/ivysettings.xml\n",
      "org.apache.spark#spark-sql-kafka-0-10_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-3e5bd420-c6e5-47c5-ad9c-3ad9d6345909;1.0\n",
      "\tconfs: [default]\n",
      "\tfound org.apache.spark#spark-sql-kafka-0-10_2.12;3.0.3 in central\n",
      "\tfound org.apache.spark#spark-token-provider-kafka-0-10_2.12;3.0.3 in central\n",
      "\tfound org.apache.kafka#kafka-clients;2.4.1 in central\n",
      "\tfound com.github.luben#zstd-jni;1.4.4-3 in central\n",
      "\tfound org.lz4#lz4-java;1.7.1 in central\n",
      "\tfound org.xerial.snappy#snappy-java;1.1.8.2 in central\n",
      "\tfound org.slf4j#slf4j-api;1.7.30 in central\n",
      "\tfound org.spark-project.spark#unused;1.0.0 in central\n",
      "\tfound org.apache.commons#commons-pool2;2.6.2 in central\n",
      ":: resolution report :: resolve 311ms :: artifacts dl 7ms\n",
      "\t:: modules in use:\n",
      "\tcom.github.luben#zstd-jni;1.4.4-3 from central in [default]\n",
      "\torg.apache.commons#commons-pool2;2.6.2 from central in [default]\n",
      "\torg.apache.kafka#kafka-clients;2.4.1 from central in [default]\n",
      "\torg.apache.spark#spark-sql-kafka-0-10_2.12;3.0.3 from central in [default]\n",
      "\torg.apache.spark#spark-token-provider-kafka-0-10_2.12;3.0.3 from central in [default]\n",
      "\torg.lz4#lz4-java;1.7.1 from central in [default]\n",
      "\torg.slf4j#slf4j-api;1.7.30 from central in [default]\n",
      "\torg.spark-project.spark#unused;1.0.0 from central in [default]\n",
      "\torg.xerial.snappy#snappy-java;1.1.8.2 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   9   |   0   |   0   |   0   ||   9   |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-3e5bd420-c6e5-47c5-ad9c-3ad9d6345909\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 9 already retrieved (0kB/8ms)\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.session import SparkSession\n",
    "\n",
    "spark = (SparkSession.builder\n",
    "    .appName(\"Processing and Serving in Streaming\")\n",
    "    .config(\"spark.sql.warehouse.dir\",\"hdfs://localhost:9000/warehouse\")\n",
    "    .enableHiveSupport()\n",
    "    .getOrCreate())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='2.3'></a>\n",
    "### 2.3 Reading of CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "marketing_info = (spark.read.option(\"inferSchema\", \"true\")\n",
    "                     .option(\"header\", \"true\")\n",
    "                     .csv(\"/home/osbdet/notebooks/Group_project/Strategies_Activity.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_str</th>\n",
       "      <th>Activity</th>\n",
       "      <th>Marketing</th>\n",
       "      <th>followers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1499694732007690241</td>\n",
       "      <td>MODERATE-MEDIUM</td>\n",
       "      <td>S6</td>\n",
       "      <td>188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1499694731894435843</td>\n",
       "      <td>ADICT</td>\n",
       "      <td>S1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1499694731617611778</td>\n",
       "      <td>MEDIUM</td>\n",
       "      <td>S8</td>\n",
       "      <td>525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1499694731449798658</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>S3</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1499694730808070144</td>\n",
       "      <td>LOW</td>\n",
       "      <td>S10</td>\n",
       "      <td>1280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127553</th>\n",
       "      <td>1497544615238385664</td>\n",
       "      <td>LOW-LOW</td>\n",
       "      <td>S11</td>\n",
       "      <td>1893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127554</th>\n",
       "      <td>1497544615167098883</td>\n",
       "      <td>MODERATE-MEDIUM</td>\n",
       "      <td>S6</td>\n",
       "      <td>198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127555</th>\n",
       "      <td>1497544615054176258</td>\n",
       "      <td>LOW</td>\n",
       "      <td>S10</td>\n",
       "      <td>1252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127556</th>\n",
       "      <td>1497544614856777733</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>S3</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127557</th>\n",
       "      <td>1497544614194163712</td>\n",
       "      <td>HIGH-HIGH</td>\n",
       "      <td>S2</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>127558 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     id_str         Activity Marketing  followers\n",
       "0       1499694732007690241  MODERATE-MEDIUM        S6        188\n",
       "1       1499694731894435843            ADICT        S1          1\n",
       "2       1499694731617611778           MEDIUM        S8        525\n",
       "3       1499694731449798658             HIGH        S3         49\n",
       "4       1499694730808070144              LOW       S10       1280\n",
       "...                     ...              ...       ...        ...\n",
       "127553  1497544615238385664          LOW-LOW       S11       1893\n",
       "127554  1497544615167098883  MODERATE-MEDIUM        S6        198\n",
       "127555  1497544615054176258              LOW       S10       1252\n",
       "127556  1497544614856777733             HIGH        S3         25\n",
       "127557  1497544614194163712        HIGH-HIGH        S2         19\n",
       "\n",
       "[127558 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "marketing_info.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='2.4'></a>\n",
    "### 2.4 Reading tweets from the kafka topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "kafka_input_topic = \"tweets\"\n",
    "kafka_group_id = \"IE\"\n",
    "\n",
    "tweets_events = (spark.readStream.format(\"kafka\")\n",
    "                         .option(\"kafka.bootstrap.servers\", \"localhost:9092\")\n",
    "                         .option(\"subscribe\", kafka_input_topic)\n",
    "                         .option(\"startingOffsets\", \"latest\")\n",
    "                         .option(\"kafka.group.id\", kafka_group_id)\n",
    "                         .load() \n",
    "                         .selectExpr(\"CAST(key AS STRING)\", \"CAST(value AS STRING)\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='2.5'></a>\n",
    "### 2.5 Creation of an specific dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import concat, lit\n",
    "\n",
    "TweetsEvents = (tweets_events.select(split(\"value\",'\\|').alias(\"fields\")) \\\n",
    "                             .withColumn(\"timestamp_str\",col(\"fields\").getItem(0)) \\\n",
    "                             .withColumn(\"created_at\",col(\"timestamp_str\").cast(TimestampType()))\\\n",
    "                             .withColumn(\"lang\",col(\"fields\").getItem(11)) \\\n",
    "                             .withColumn(\"id_str\",col(\"fields\").getItem(1)) \\\n",
    "                             .withColumn(\"user_followers_count\",col(\"fields\").getItem(20)) \\\n",
    "                             .where(col(\"user_followers_count\")>=200)\n",
    "                             .select(\"created_at\", \"lang\", \"id_str\", \"user_followers_count\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='2.6'></a>\n",
    "### 2.6 Join, and launch to MariaDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "TweetsMarketingSuggestion= TweetsEvents.join(marketing_info, \"id_str\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We specify where the table is going to be upload, in this case in MariaDB in the table created before with our sql.file launched in step 3.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def foreach_batch_function(df, epoch_id):\n",
    "    print (\"Batch %d received\" % epoch_id)\n",
    "    \n",
    "    # databases connection properties\n",
    "    url = \"jdbc:mariadb://localhost:3306/DBS_tweets\"\n",
    "    table = \"final_tweets\"\n",
    "    mode = \"append\"\n",
    "    props = {\"user\": \"osbdet\",\n",
    "             \"password\":\"osbdet123$\", \n",
    "             \"driver\":\"org.mariadb.jdbc.Driver\"}\n",
    "    (df.select(\"created_at\", \n",
    "              \"lang\", \n",
    "              \"id_str\", \n",
    "              \"user_followers_count\",\n",
    "              \"Activity\",\n",
    "              \"Marketing\")\n",
    "        .write\n",
    "        .jdbc(url,table,mode,props)\n",
    "     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We launch the creation of the info in streaming in MariaDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0 received\n",
      "Batch 1 received\n",
      "Batch 2 received\n",
      "Batch 3 received\n",
      "Batch 4 received\n",
      "Batch 5 received\n",
      "Batch 6 received\n",
      "Batch 7 received\n",
      "Batch 8 received\n",
      "Batch 9 received\n",
      "Batch 10 received\n",
      "Batch 11 received\n",
      "Batch 12 received\n",
      "Batch 13 received\n",
      "Batch 14 received\n",
      "Batch 15 received\n",
      "Batch 16 received\n",
      "Batch 17 received\n",
      "Batch 18 received\n",
      "Batch 19 received\n",
      "Batch 20 received\n",
      "Batch 21 received\n",
      "Batch 22 received\n",
      "Batch 23 received\n",
      "Batch 24 received\n",
      "Batch 25 received\n",
      "Batch 26 received\n",
      "Batch 27 received\n",
      "Batch 28 received\n",
      "Batch 29 received\n",
      "Batch 30 received\n",
      "Batch 31 received\n",
      "Batch 32 received\n",
      "Batch 33 received\n",
      "Batch 34 received\n",
      "Batch 35 received\n",
      "Batch 36 received\n",
      "Batch 37 received\n",
      "Batch 38 received\n",
      "Batch 39 received\n",
      "Batch 40 received\n",
      "Batch 41 received\n",
      "Batch 42 received\n",
      "Batch 43 received\n",
      "Batch 44 received\n",
      "Batch 45 received\n",
      "Batch 46 received\n",
      "Batch 47 received\n",
      "Batch 48 received\n",
      "Batch 49 received\n",
      "Batch 50 received\n",
      "Batch 51 received\n",
      "Batch 52 received\n",
      "Batch 53 received\n",
      "Batch 54 received\n",
      "Batch 55 received\n",
      "Batch 56 received\n",
      "Batch 57 received\n",
      "Batch 58 received\n",
      "Batch 59 received\n",
      "Batch 60 received\n",
      "Batch 61 received\n",
      "Batch 62 received\n",
      "Batch 63 received\n",
      "Batch 64 received\n",
      "Batch 65 received\n",
      "Batch 66 received\n",
      "Batch 67 received\n",
      "Batch 68 received\n",
      "Batch 69 received\n",
      "Batch 70 received\n",
      "Batch 71 received\n",
      "Batch 72 received\n",
      "Batch 73 received\n",
      "Batch 74 received\n",
      "Batch 75 received\n",
      "Batch 76 received\n",
      "Batch 77 received\n",
      "Batch 78 received\n",
      "Batch 79 received\n",
      "Batch 80 received\n",
      "Batch 81 received\n",
      "Batch 82 received\n",
      "Batch 83 received\n",
      "Batch 84 received\n",
      "Batch 85 received\n",
      "Batch 86 received\n",
      "Batch 87 received\n",
      "Batch 88 received\n",
      "Batch 89 received\n",
      "Batch 90 received\n",
      "Batch 91 received\n",
      "Batch 92 received\n",
      "Batch 93 received\n",
      "Batch 94 received\n",
      "Batch 95 received\n",
      "Batch 96 received\n",
      "Batch 97 received\n",
      "Batch 98 received\n",
      "Batch 99 received\n",
      "Batch 100 received\n",
      "Batch 101 received\n",
      "Batch 102 received\n",
      "Batch 103 received\n",
      "Batch 104 received\n",
      "Batch 105 received\n",
      "Batch 106 received\n",
      "Batch 107 received\n",
      "Batch 108 received\n",
      "Batch 109 received\n",
      "Batch 110 received\n",
      "Batch 111 received\n",
      "Batch 112 received\n",
      "Batch 113 received\n",
      "Batch 114 received\n",
      "Batch 115 received\n",
      "Batch 116 received\n",
      "Batch 117 received\n",
      "Batch 118 received\n",
      "Batch 119 received\n",
      "Batch 120 received\n",
      "Batch 121 received\n",
      "Batch 122 received\n",
      "Batch 123 received\n",
      "Batch 124 received\n",
      "Batch 125 received\n",
      "Batch 126 received\n",
      "Batch 127 received\n",
      "Batch 128 received\n",
      "Batch 129 received\n",
      "Batch 130 received\n",
      "Batch 131 received\n",
      "Batch 132 received\n",
      "Batch 133 received\n",
      "Batch 134 received\n",
      "Batch 135 received\n",
      "Batch 136 received\n",
      "Batch 137 received\n",
      "Batch 138 received\n",
      "Batch 139 received\n",
      "Batch 140 received\n",
      "Batch 141 received\n",
      "Batch 142 received\n",
      "Batch 143 received\n",
      "Batch 144 received\n",
      "Batch 145 received\n",
      "Batch 146 received\n",
      "Batch 147 received\n",
      "Batch 148 received\n",
      "Batch 149 received\n",
      "Batch 150 received\n",
      "Batch 151 received\n",
      "Batch 152 received\n",
      "Batch 153 received\n",
      "Batch 154 received\n",
      "Batch 155 received\n",
      "Batch 156 received\n",
      "Batch 157 received\n",
      "Batch 158 received\n",
      "Batch 159 received\n",
      "Batch 160 received\n",
      "Batch 161 received\n",
      "Batch 162 received\n",
      "Batch 163 received\n",
      "Batch 164 received\n",
      "Batch 165 received\n",
      "Batch 166 received\n",
      "Batch 167 received\n",
      "Batch 168 received\n",
      "Batch 169 received\n",
      "Batch 170 received\n",
      "Batch 171 received\n",
      "Batch 172 received\n",
      "Batch 173 received\n",
      "Batch 174 received\n",
      "Batch 175 received\n",
      "Batch 176 received\n",
      "Batch 177 received\n",
      "Batch 178 received\n",
      "Batch 179 received\n",
      "Batch 180 received\n",
      "Batch 181 received\n",
      "Batch 182 received\n",
      "Batch 183 received\n",
      "Batch 184 received\n",
      "Batch 185 received\n",
      "Batch 186 received\n",
      "Batch 187 received\n",
      "Batch 188 received\n",
      "Batch 189 received\n",
      "Batch 190 received\n",
      "Batch 191 received\n",
      "Batch 192 received\n",
      "Batch 193 received\n",
      "Batch 194 received\n",
      "Batch 195 received\n",
      "Batch 196 received\n",
      "Batch 197 received\n",
      "Batch 198 received\n",
      "Batch 199 received\n",
      "Batch 200 received\n",
      "Batch 201 received\n",
      "Batch 202 received\n",
      "Batch 203 received\n",
      "Batch 204 received\n",
      "Batch 205 received\n",
      "Batch 206 received\n",
      "Batch 207 received\n",
      "Batch 208 received\n",
      "Batch 209 received\n",
      "Batch 210 received\n",
      "Batch 211 received\n",
      "Batch 212 received\n",
      "Batch 213 received\n",
      "Batch 214 received\n",
      "Batch 215 received\n",
      "Batch 216 received\n",
      "Batch 217 received\n",
      "Batch 218 received\n",
      "Batch 219 received\n",
      "Batch 220 received\n",
      "Batch 221 received\n",
      "Batch 222 received\n",
      "Batch 223 received\n",
      "Batch 224 received\n",
      "Batch 225 received\n",
      "Batch 226 received\n",
      "Batch 227 received\n",
      "Batch 228 received\n",
      "Batch 229 received\n",
      "Batch 230 received\n",
      "Batch 231 received\n",
      "Batch 232 received\n",
      "Batch 233 received\n",
      "Batch 234 received\n",
      "Batch 235 received\n",
      "Batch 236 received\n",
      "Batch 237 received\n",
      "Batch 238 received\n",
      "Batch 239 received\n",
      "Batch 240 received\n",
      "Batch 241 received\n",
      "Batch 242 received\n",
      "Batch 243 received\n",
      "Batch 244 received\n",
      "Batch 245 received\n",
      "Batch 246 received\n",
      "Batch 247 received\n",
      "Batch 248 received\n",
      "Batch 249 received\n",
      "Batch 250 received\n",
      "Batch 251 received\n",
      "Batch 252 received\n",
      "Batch 253 received\n",
      "Batch 254 received\n",
      "Batch 255 received\n",
      "Batch 256 received\n",
      "Batch 257 received\n",
      "Batch 258 received\n",
      "Batch 259 received\n",
      "Batch 260 received\n",
      "Batch 261 received\n",
      "Batch 262 received\n",
      "Batch 263 received\n",
      "Batch 264 received\n",
      "Batch 265 received\n",
      "Batch 266 received\n",
      "Batch 267 received\n",
      "Batch 268 received\n",
      "Batch 269 received\n",
      "Batch 270 received\n",
      "Batch 271 received\n",
      "Batch 272 received\n",
      "Batch 273 received\n",
      "Batch 274 received\n",
      "Batch 275 received\n",
      "Batch 276 received\n",
      "Batch 277 received\n",
      "Batch 278 received\n",
      "Batch 279 received\n",
      "Batch 280 received\n",
      "Batch 281 received\n",
      "Batch 282 received\n",
      "Batch 283 received\n",
      "Batch 284 received\n",
      "Batch 285 received\n",
      "Batch 286 received\n",
      "Batch 287 received\n",
      "Batch 288 received\n",
      "Batch 289 received\n",
      "Batch 290 received\n",
      "Batch 291 received\n",
      "Batch 292 received\n",
      "Batch 293 received\n",
      "Batch 294 received\n",
      "Batch 295 received\n",
      "Batch 296 received\n",
      "Batch 297 received\n",
      "Batch 298 received\n",
      "Batch 299 received\n",
      "Batch 300 received\n",
      "Batch 301 received\n",
      "Batch 302 received\n",
      "Batch 303 received\n",
      "Batch 304 received\n",
      "Batch 305 received\n",
      "Batch 306 received\n",
      "Batch 307 received\n",
      "Batch 308 received\n",
      "Batch 309 received\n",
      "Batch 310 received\n",
      "Batch 311 received\n",
      "Batch 312 received\n",
      "Batch 313 received\n",
      "Batch 314 received\n",
      "Batch 315 received\n",
      "Batch 316 received\n",
      "Batch 317 received\n",
      "Batch 318 received\n",
      "Batch 319 received\n",
      "Batch 320 received\n",
      "Batch 321 received\n",
      "Batch 322 received\n",
      "Batch 323 received\n",
      "Batch 324 received\n",
      "Batch 325 received\n",
      "Batch 326 received\n",
      "Batch 327 received\n",
      "Batch 328 received\n",
      "Batch 329 received\n",
      "Batch 330 received\n",
      "Batch 331 received\n",
      "Batch 332 received\n",
      "Batch 333 received\n",
      "Batch 334 received\n",
      "Batch 335 received\n",
      "Batch 336 received\n",
      "Batch 337 received\n",
      "Batch 338 received\n",
      "Batch 339 received\n",
      "Batch 340 received\n",
      "Batch 341 received\n",
      "Batch 342 received\n",
      "Batch 343 received\n",
      "Batch 344 received\n",
      "Batch 345 received\n",
      "Batch 346 received\n",
      "Batch 347 received\n",
      "Batch 348 received\n",
      "Batch 349 received\n",
      "Batch 350 received\n",
      "Batch 351 received\n",
      "Batch 352 received\n",
      "Batch 353 received\n",
      "Batch 354 received\n",
      "Batch 355 received\n",
      "Batch 356 received\n",
      "Batch 357 received\n",
      "Batch 358 received\n",
      "Batch 359 received\n",
      "Batch 360 received\n",
      "Batch 361 received\n",
      "Batch 362 received\n",
      "Batch 363 received\n",
      "Batch 364 received\n",
      "Batch 365 received\n",
      "Batch 366 received\n",
      "Batch 367 received\n",
      "Batch 368 received\n",
      "Batch 369 received\n",
      "Batch 370 received\n",
      "Batch 371 received\n",
      "Batch 372 received\n",
      "Batch 373 received\n",
      "Batch 374 received\n",
      "Batch 375 received\n",
      "Batch 376 received\n",
      "Batch 377 received\n",
      "Batch 378 received\n",
      "Batch 379 received\n",
      "Batch 380 received\n",
      "Batch 381 received\n",
      "Batch 382 received\n",
      "Batch 383 received\n",
      "Batch 384 received\n",
      "Batch 385 received\n",
      "Batch 386 received\n",
      "Batch 387 received\n",
      "Batch 388 received\n",
      "Batch 389 received\n",
      "Batch 390 received\n",
      "Batch 391 received\n",
      "Batch 392 received\n",
      "Batch 393 received\n",
      "Batch 394 received\n",
      "Batch 395 received\n",
      "Batch 396 received\n",
      "Batch 397 received\n",
      "Batch 398 received\n",
      "Batch 399 received\n",
      "Batch 400 received\n",
      "Batch 401 received\n",
      "Batch 402 received\n",
      "Batch 403 received\n",
      "Batch 404 received\n",
      "Batch 405 received\n",
      "Batch 406 received\n",
      "Batch 407 received\n",
      "Batch 408 received\n",
      "Batch 409 received\n",
      "Batch 410 received\n",
      "Batch 411 received\n",
      "Batch 412 received\n",
      "Batch 413 received\n",
      "Batch 414 received\n",
      "Batch 415 received\n",
      "Batch 416 received\n",
      "Batch 417 received\n",
      "Batch 418 received\n",
      "Batch 419 received\n",
      "Batch 420 received\n",
      "Batch 421 received\n",
      "Batch 422 received\n",
      "Batch 423 received\n",
      "Batch 424 received\n",
      "Batch 425 received\n",
      "Batch 426 received\n",
      "Batch 427 received\n",
      "Batch 428 received\n",
      "Batch 429 received\n",
      "Batch 430 received\n",
      "Batch 431 received\n",
      "Batch 432 received\n",
      "Batch 433 received\n",
      "Batch 434 received\n",
      "Batch 435 received\n",
      "Batch 436 received\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 437 received\n",
      "Batch 438 received\n",
      "Batch 439 received\n",
      "Batch 440 received\n",
      "Batch 441 received\n",
      "Batch 442 received\n",
      "Batch 443 received\n",
      "Batch 444 received\n",
      "Batch 445 received\n",
      "Batch 446 received\n",
      "Batch 447 received\n",
      "Batch 448 received\n",
      "Batch 449 received\n",
      "Batch 450 received\n",
      "Batch 451 received\n",
      "Batch 452 received\n",
      "Batch 453 received\n",
      "Batch 454 received\n",
      "Batch 455 received\n",
      "Batch 456 received\n",
      "Batch 457 received\n",
      "Batch 458 received\n",
      "Batch 459 received\n",
      "Batch 460 received\n",
      "Batch 461 received\n",
      "Batch 462 received\n",
      "Batch 463 received\n",
      "Batch 464 received\n",
      "Batch 465 received\n",
      "Batch 466 received\n",
      "Batch 467 received\n",
      "Batch 468 received\n",
      "Batch 469 received\n",
      "Batch 470 received\n",
      "Batch 471 received\n",
      "Batch 472 received\n",
      "Batch 473 received\n",
      "Batch 474 received\n",
      "Batch 475 received\n",
      "Batch 476 received\n",
      "Batch 477 received\n",
      "Batch 478 received\n",
      "Batch 479 received\n",
      "Batch 480 received\n",
      "Batch 481 received\n",
      "Batch 482 received\n",
      "Batch 483 received\n",
      "Batch 484 received\n",
      "Batch 485 received\n",
      "Batch 486 received\n",
      "Batch 487 received\n",
      "Batch 488 received\n",
      "Batch 489 received\n",
      "Batch 490 received\n",
      "Batch 491 received\n",
      "Batch 492 received\n",
      "Batch 493 received\n",
      "Batch 494 received\n",
      "Batch 495 received\n",
      "Batch 496 received\n",
      "Batch 497 received\n",
      "Batch 498 received\n",
      "Batch 499 received\n",
      "Batch 500 received\n",
      "Batch 501 received\n",
      "Batch 502 received\n",
      "Batch 503 received\n",
      "Batch 504 received\n",
      "Batch 505 received\n",
      "Batch 506 received\n",
      "Batch 507 received\n",
      "Batch 508 received\n",
      "Batch 509 received\n",
      "Batch 510 received\n",
      "Batch 511 received\n",
      "Batch 512 received\n",
      "Batch 513 received\n",
      "Batch 514 received\n",
      "Batch 515 received\n",
      "Batch 516 received\n",
      "Batch 517 received\n",
      "Batch 518 received\n",
      "Batch 519 received\n",
      "Batch 520 received\n",
      "Batch 521 received\n",
      "Batch 522 received\n",
      "Batch 523 received\n",
      "Batch 524 received\n",
      "Batch 525 received\n",
      "Batch 526 received\n",
      "Batch 527 received\n",
      "Batch 528 received\n",
      "Batch 529 received\n",
      "Batch 530 received\n",
      "Batch 531 received\n",
      "Batch 532 received\n",
      "Batch 533 received\n",
      "Batch 534 received\n",
      "Batch 535 received\n",
      "Batch 536 received\n",
      "Batch 537 received\n",
      "Batch 538 received\n",
      "Batch 539 received\n",
      "Batch 540 received\n",
      "Batch 541 received\n",
      "Batch 542 received\n",
      "Batch 543 received\n",
      "Batch 544 received\n",
      "Batch 545 received\n",
      "Batch 546 received\n",
      "Batch 547 received\n",
      "Batch 548 received\n",
      "Batch 549 received\n",
      "Batch 550 received\n",
      "Batch 551 received\n",
      "Batch 552 received\n",
      "Batch 553 received\n",
      "Batch 554 received\n",
      "Batch 555 received\n",
      "Batch 556 received\n",
      "Batch 557 received\n",
      "Batch 558 received\n",
      "Batch 559 received\n",
      "Batch 560 received\n",
      "Batch 561 received\n",
      "Batch 562 received\n",
      "Batch 563 received\n",
      "Batch 564 received\n",
      "Batch 565 received\n",
      "Batch 566 received\n",
      "Batch 567 received\n",
      "Batch 568 received\n",
      "Batch 569 received\n",
      "Batch 570 received\n",
      "Batch 571 received\n",
      "Batch 572 received\n",
      "Batch 573 received\n",
      "Batch 574 received\n",
      "Batch 575 received\n",
      "Batch 576 received\n",
      "Batch 577 received\n",
      "Batch 578 received\n",
      "Batch 579 received\n",
      "Batch 580 received\n",
      "Batch 581 received\n",
      "Batch 582 received\n",
      "Batch 583 received\n",
      "Batch 584 received\n",
      "Batch 585 received\n",
      "Batch 586 received\n",
      "Batch 587 received\n",
      "Batch 588 received\n",
      "Batch 589 received\n",
      "Batch 590 received\n",
      "Batch 591 received\n",
      "Batch 592 received\n",
      "Batch 593 received\n",
      "Batch 594 received\n",
      "Batch 595 received\n",
      "Batch 596 received\n",
      "Batch 597 received\n",
      "Batch 598 received\n",
      "Batch 599 received\n",
      "Batch 600 received\n",
      "Batch 601 received\n",
      "Batch 602 received\n",
      "Batch 603 received\n",
      "Batch 604 received\n",
      "Batch 605 received\n",
      "Batch 606 received\n",
      "Batch 607 received\n",
      "Batch 608 received\n",
      "Batch 609 received\n",
      "Batch 610 received\n",
      "Batch 611 received\n",
      "Batch 612 received\n",
      "Batch 613 received\n",
      "Batch 614 received\n",
      "Batch 615 received\n",
      "Batch 616 received\n",
      "Batch 617 received\n",
      "Batch 618 received\n",
      "Batch 619 received\n",
      "Batch 620 received\n",
      "Batch 621 received\n",
      "Batch 622 received\n",
      "Batch 623 received\n",
      "Batch 624 received\n",
      "Batch 625 received\n",
      "Batch 626 received\n",
      "Batch 627 received\n",
      "Batch 628 received\n",
      "Batch 629 received\n",
      "Batch 630 received\n",
      "Batch 631 received\n",
      "Batch 632 received\n",
      "Batch 633 received\n",
      "Batch 634 received\n",
      "Batch 635 received\n",
      "Batch 636 received\n",
      "Batch 637 received\n",
      "Batch 638 received\n",
      "Batch 639 received\n",
      "Batch 640 received\n",
      "Batch 641 received\n",
      "Batch 642 received\n",
      "Batch 643 received\n"
     ]
    }
   ],
   "source": [
    "query = (TweetsMarketingSuggestion.writeStream\\\n",
    "                               .foreachBatch(lambda df,epochId:foreach_batch_function(df, epochId))).start()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
